{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoXk3Svf9Acf"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27308,
     "status": "ok",
     "timestamp": 1761041075301,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "TzwYs3Za83Ev"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIxWwcKQE2UL"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1761041075314,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "zqu1hX4QEzJt"
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgNcyytjFBW-"
   },
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1761041075319,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "hK-9iD4EFDr0"
   },
   "outputs": [],
   "source": [
    "def stop_words(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie2ByEHBFKFe"
   },
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1761041075322,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "fvjE2TyHFNxE"
   },
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    doc = nlp(text)\n",
    "    return [stemmer.stem(token.text) for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cswFAvyTFRbP"
   },
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1761041075326,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "fWgxmwFOFV92"
   },
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5o-fU6KFXXA"
   },
   "source": [
    "### Parts Of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1761041075328,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "ICEFD5L9FdCx"
   },
   "outputs": [],
   "source": [
    "def pos_tagging(text):\n",
    "    doc = nlp(text)\n",
    "    return [(token.text, token.pos_) for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sriNn-GFgoL"
   },
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1761041075332,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "oblriu30Fk1p"
   },
   "outputs": [],
   "source": [
    "def ner(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLoHdym1Fn_S"
   },
   "source": [
    "### Full Pipeline - stemming OR lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1761041075334,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "MsPOjG6lFz7A"
   },
   "outputs": [],
   "source": [
    "def run_all(text, mode):\n",
    "    result = {\n",
    "        \"tokenize\": tokenize(text),\n",
    "        \"stop_words\": stop_words(text),\n",
    "        \"pos_tagging\": pos_tagging(text),\n",
    "        \"ner\": ner(text),\n",
    "    }\n",
    "    if (mode == \"stemming\"):\n",
    "        result[\"stemmed\"] = stemming(text)\n",
    "    elif (mode == \"lemmatization\"):\n",
    "        result[\"lemmatized\"] = lemmatization(text)\n",
    "    else:\n",
    "        result[\"lemmatized\"] = lemmatization(text)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EBvx6lBIcEM"
   },
   "source": [
    "### Visibility\n",
    "On 'Dataset' tab - when user select 'Full Pipeline' then only we want to allow choose 'Stemming' or 'Lemmatization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1761041075337,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "2N_67h3MIziQ"
   },
   "outputs": [],
   "source": [
    "def toggle_visibility(nlp_choice):\n",
    "    if nlp_choice == \"Full Pipeline\":\n",
    "        return gr.update(visible=True)\n",
    "    else:\n",
    "        return gr.update(visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8Tu2kNgF1fV"
   },
   "source": [
    "### Reading Columns of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1761041075351,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "JgZp2ipLF8cM"
   },
   "outputs": [],
   "source": [
    "def get_columns(file):\n",
    "    if file is None:\n",
    "        return {\"error\": \"No file uploaded.\"}\n",
    "    elif file.name.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file.name)\n",
    "    else:\n",
    "        df = pd.read_excel(file.name)\n",
    "    return gr.update(choices=[\"All Columns\"] + df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lrfp6MUF9u0"
   },
   "source": [
    "### File Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1761041075358,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "x-AbQOcQGKhY"
   },
   "outputs": [],
   "source": [
    "def process_file(file, column, nlp_choice, mode=\"lemmatization\"):\n",
    "    if not file:\n",
    "        return {\"error\": \"No file uploaded.\"}\n",
    "    if not column:\n",
    "        return {\"error\": \"No column selected.\"}\n",
    "    if not nlp_choice:\n",
    "        return {\"error\": \"No NLP function selected.\"}\n",
    "\n",
    "    # Load file\n",
    "    if file.name.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file)\n",
    "    elif file.name.endswith((\".xlsx\", \".xls\")):\n",
    "        df = pd.read_excel(file)\n",
    "    else:\n",
    "        return {\"error\": \"Unsupported file type.\"}\n",
    "\n",
    "    # Determine columns\n",
    "    columns = [column] if column != \"All Columns\" else df.columns.tolist()\n",
    "\n",
    "    # NLP function map\n",
    "    nlp_map = {\n",
    "        \"Tokenization\": tokenize,\n",
    "        \"Stop Words\": stop_words,\n",
    "        \"Stemming\": stemming,\n",
    "        \"Lemmatization\": lemmatization,\n",
    "        \"POS Tagging\": pos_tagging,\n",
    "        \"NER\": ner,\n",
    "    }\n",
    "\n",
    "    for col in columns:\n",
    "        def process_text(text):\n",
    "            text = str(text)\n",
    "            try:\n",
    "                if nlp_choice == \"Full Pipeline\":\n",
    "                    return run_all(text, mode)\n",
    "\n",
    "                func = nlp_map.get(nlp_choice)\n",
    "                return func(text) if func else {}\n",
    "            except Exception as e:\n",
    "                return {\"error\": str(e)}\n",
    "\n",
    "        df[f\"{col}_processed\"] = df[col].apply(process_text)\n",
    "\n",
    "    return df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAVvfjsUGQ77"
   },
   "source": [
    "### Tabs UI - Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2182,
     "status": "ok",
     "timestamp": 1761041077545,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "cujwMluQGTsi"
   },
   "outputs": [],
   "source": [
    "text_tabs = gr.TabbedInterface(\n",
    "    [\n",
    "        gr.Interface(fn=lambda text, mode: run_all(text, mode), inputs=[gr.Textbox(label=\"Text\"), gr.Radio([\"stemming\", \"lemmatization\"])], outputs=\"json\", title=\"Full Pipeline\"),\n",
    "        gr.Interface(fn=tokenize, inputs=\"text\", outputs=\"json\", title=\"Tokenization\"),\n",
    "        gr.Interface(fn=stop_words, inputs=\"text\", outputs=\"json\", title=\"Stop Words\"),\n",
    "        gr.Interface(fn=stemming, inputs=\"text\", outputs=\"json\", title=\"Stemming\"),\n",
    "        gr.Interface(fn=lemmatization, inputs=\"text\", outputs=\"json\", title=\"Lemmatization\"),\n",
    "        gr.Interface(fn=pos_tagging, inputs=\"text\", outputs=\"json\", title=\"POS_Tagging\"),\n",
    "        gr.Interface(fn=ner, inputs=\"text\", outputs=\"json\", title=\"NER\"),\n",
    "    ],\n",
    "    tab_names=[\"Full Pipeline\", \"Tokenization\", \"Stop Words\", \"Stemming\", \"Lemmatization\", \"POS_Tagging\", \"NER\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5B-TTI8Gb0h"
   },
   "source": [
    "### Block UI - Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1761041078464,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "Xb_P6X5DGfqu"
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as dataset_tab:\n",
    "    gr.Markdown(\"## Run NLP on Uploaded File\")\n",
    "    file_input = gr.File(label=\"Upload Your File\", type=\"filepath\")\n",
    "    column_dropdown = gr.Radio([\"All Columns\"], value=\"All Columns\", label=\"Select Column to Process\")\n",
    "    nlp_choice = gr.Radio([\"Full Pipeline\", \"Tokenization\", \"Stop Words\", \"POS Tagging\", \"NER\", \"Stemming\", \"Lemmatization\"], label=\"Select NLP Function\")\n",
    "    mode = gr.Radio([\"stemming\", \"lemmatization\"], visible=False)\n",
    "    output = gr.JSON(label=\"Processed Data\")\n",
    "    run_btn = gr.Button(\"Run NLP\")\n",
    "\n",
    "    nlp_choice.change(fn=toggle_visibility, inputs=nlp_choice, outputs=mode)\n",
    "    file_input.change(fn=get_columns, inputs=file_input, outputs=column_dropdown)\n",
    "    run_btn.click(fn=process_file, inputs=[file_input, column_dropdown, nlp_choice, mode], outputs=output)\n",
    "\n",
    "app = gr.TabbedInterface([text_tabs, dataset_tab], [\"Text\", \"Dataset\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cb1tFtRcGyzN"
   },
   "source": [
    "### Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 1572,
     "status": "ok",
     "timestamp": 1761041080043,
     "user": {
      "displayName": "Rayan Tanzeem",
      "userId": "14469347407249511451"
     },
     "user_tz": -300
    },
    "id": "-VqN02L8G06U",
    "outputId": "84df2a79-58ef-4148-b357-70e32164f79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://a7032e7d1edb3f28dd.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a7032e7d1edb3f28dd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNuZCxMOiVBzLSN/Gu4DhiT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
