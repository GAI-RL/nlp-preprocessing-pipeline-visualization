{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuZCxMOiVBzLSN/Gu4DhiT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"qoXk3Svf9Acf"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"TzwYs3Za83Ev","executionInfo":{"status":"ok","timestamp":1761041075301,"user_tz":-300,"elapsed":27308,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"outputs":[],"source":["import pandas as pd\n","import gradio as gr\n","import spacy\n","from nltk.stem import PorterStemmer\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","stemmer = PorterStemmer()"]},{"cell_type":"markdown","source":["### Tokenization"],"metadata":{"id":"LIxWwcKQE2UL"}},{"cell_type":"code","source":["def tokenize(text):\n","    doc = nlp(text)\n","    return [token.text for token in doc]"],"metadata":{"id":"zqu1hX4QEzJt","executionInfo":{"status":"ok","timestamp":1761041075314,"user_tz":-300,"elapsed":3,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Stop Words"],"metadata":{"id":"BgNcyytjFBW-"}},{"cell_type":"code","source":["def stop_words(text):\n","    doc = nlp(text)\n","    return [token.text for token in doc if token.is_stop and not token.is_punct]"],"metadata":{"id":"hK-9iD4EFDr0","executionInfo":{"status":"ok","timestamp":1761041075319,"user_tz":-300,"elapsed":2,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Stemming"],"metadata":{"id":"Ie2ByEHBFKFe"}},{"cell_type":"code","source":["def stemming(text):\n","    doc = nlp(text)\n","    return [stemmer.stem(token.text) for token in doc]"],"metadata":{"id":"fvjE2TyHFNxE","executionInfo":{"status":"ok","timestamp":1761041075322,"user_tz":-300,"elapsed":1,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Lemmatization"],"metadata":{"id":"cswFAvyTFRbP"}},{"cell_type":"code","source":["def lemmatization(text):\n","    doc = nlp(text)\n","    return [token.lemma_ for token in doc]"],"metadata":{"id":"fWgxmwFOFV92","executionInfo":{"status":"ok","timestamp":1761041075326,"user_tz":-300,"elapsed":2,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Parts Of Speech Tagging"],"metadata":{"id":"x5o-fU6KFXXA"}},{"cell_type":"code","source":["def pos_tagging(text):\n","    doc = nlp(text)\n","    return [(token.text, token.pos_) for token in doc]"],"metadata":{"id":"ICEFD5L9FdCx","executionInfo":{"status":"ok","timestamp":1761041075328,"user_tz":-300,"elapsed":1,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Named Entity Recognition"],"metadata":{"id":"5sriNn-GFgoL"}},{"cell_type":"code","source":["def ner(text):\n","    doc = nlp(text)\n","    return [(ent.text, ent.label_) for ent in doc.ents]"],"metadata":{"id":"oblriu30Fk1p","executionInfo":{"status":"ok","timestamp":1761041075332,"user_tz":-300,"elapsed":1,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Full Pipeline - stemming OR lemmatization"],"metadata":{"id":"wLoHdym1Fn_S"}},{"cell_type":"code","source":["def run_all(text, mode):\n","    result = {\n","        \"tokenize\": tokenize(text),\n","        \"stop_words\": stop_words(text),\n","        \"pos_tagging\": pos_tagging(text),\n","        \"ner\": ner(text),\n","    }\n","    if (mode == \"stemming\"):\n","        result[\"stemmed\"] = stemming(text)\n","    elif (mode == \"lemmatization\"):\n","        result[\"lemmatized\"] = lemmatization(text)\n","    else:\n","        result[\"lemmatized\"] = lemmatization(text)\n","\n","    return result"],"metadata":{"id":"MsPOjG6lFz7A","executionInfo":{"status":"ok","timestamp":1761041075334,"user_tz":-300,"elapsed":1,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### Visibility\n","On 'Dataset' tab - when user select 'Full Pipeline' then only we want to allow choose 'Stemming' or 'Lemmatization'"],"metadata":{"id":"5EBvx6lBIcEM"}},{"cell_type":"code","source":["def toggle_visibility(nlp_choice):\n","    if nlp_choice == \"Full Pipeline\":\n","        return gr.update(visible=True)\n","    else:\n","        return gr.update(visible=False)"],"metadata":{"id":"2N_67h3MIziQ","executionInfo":{"status":"ok","timestamp":1761041075337,"user_tz":-300,"elapsed":1,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Reading Columns of Dataset"],"metadata":{"id":"h8Tu2kNgF1fV"}},{"cell_type":"code","source":["def get_columns(file):\n","    if file is None:\n","        return {\"error\": \"No file uploaded.\"}\n","    elif file.name.endswith(\".csv\"):\n","        df = pd.read_csv(file.name)\n","    else:\n","        df = pd.read_excel(file.name)\n","    return gr.update(choices=[\"All Columns\"] + df.columns.tolist())"],"metadata":{"id":"JgZp2ipLF8cM","executionInfo":{"status":"ok","timestamp":1761041075351,"user_tz":-300,"elapsed":13,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### File Processing"],"metadata":{"id":"5lrfp6MUF9u0"}},{"cell_type":"code","source":["def process_file(file, column, nlp_choice, mode=\"lemmatization\"):\n","    if not file:\n","        return {\"error\": \"No file uploaded.\"}\n","    if not column:\n","        return {\"error\": \"No column selected.\"}\n","    if not nlp_choice:\n","        return {\"error\": \"No NLP function selected.\"}\n","\n","    # Load file\n","    if file.name.endswith(\".csv\"):\n","        df = pd.read_csv(file)\n","    elif file.name.endswith((\".xlsx\", \".xls\")):\n","        df = pd.read_excel(file)\n","    else:\n","        return {\"error\": \"Unsupported file type.\"}\n","\n","    # Determine columns\n","    columns = [column] if column != \"All Columns\" else df.columns.tolist()\n","\n","    # NLP function map\n","    nlp_map = {\n","        \"Tokenization\": tokenize,\n","        \"Stop Words\": stop_words,\n","        \"Stemming\": stemming,\n","        \"Lemmatization\": lemmatization,\n","        \"POS Tagging\": pos_tagging,\n","        \"NER\": ner,\n","    }\n","\n","    for col in columns:\n","        def process_text(text):\n","            text = str(text)\n","            try:\n","                if nlp_choice == \"Full Pipeline\":\n","                    return run_all(text, mode)\n","\n","                func = nlp_map.get(nlp_choice)\n","                return func(text) if func else {}\n","            except Exception as e:\n","                return {\"error\": str(e)}\n","\n","        df[f\"{col}_processed\"] = df[col].apply(process_text)\n","\n","    return df.to_dict(orient=\"records\")"],"metadata":{"id":"x-AbQOcQGKhY","executionInfo":{"status":"ok","timestamp":1761041075358,"user_tz":-300,"elapsed":5,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Tabs UI - Gradio"],"metadata":{"id":"dAVvfjsUGQ77"}},{"cell_type":"code","source":["text_tabs = gr.TabbedInterface(\n","    [\n","        gr.Interface(fn=lambda text, mode: run_all(text, mode), inputs=[gr.Textbox(label=\"Text\"), gr.Radio([\"stemming\", \"lemmatization\"])], outputs=\"json\", title=\"Full Pipeline\"),\n","        gr.Interface(fn=tokenize, inputs=\"text\", outputs=\"json\", title=\"Tokenization\"),\n","        gr.Interface(fn=stop_words, inputs=\"text\", outputs=\"json\", title=\"Stop Words\"),\n","        gr.Interface(fn=stemming, inputs=\"text\", outputs=\"json\", title=\"Stemming\"),\n","        gr.Interface(fn=lemmatization, inputs=\"text\", outputs=\"json\", title=\"Lemmatization\"),\n","        gr.Interface(fn=pos_tagging, inputs=\"text\", outputs=\"json\", title=\"POS_Tagging\"),\n","        gr.Interface(fn=ner, inputs=\"text\", outputs=\"json\", title=\"NER\"),\n","    ],\n","    tab_names=[\"Full Pipeline\", \"Tokenization\", \"Stop Words\", \"Stemming\", \"Lemmatization\", \"POS_Tagging\", \"NER\"]\n",")"],"metadata":{"id":"cujwMluQGTsi","executionInfo":{"status":"ok","timestamp":1761041077545,"user_tz":-300,"elapsed":2182,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["### Block UI - Gradio"],"metadata":{"id":"E5B-TTI8Gb0h"}},{"cell_type":"code","source":["with gr.Blocks() as dataset_tab:\n","    gr.Markdown(\"## Run NLP on Uploaded File\")\n","    file_input = gr.File(label=\"Upload Your File\", type=\"filepath\")\n","    column_dropdown = gr.Radio([\"All Columns\"], value=\"All Columns\", label=\"Select Column to Process\")\n","    nlp_choice = gr.Radio([\"Full Pipeline\", \"Tokenization\", \"Stop Words\", \"POS Tagging\", \"NER\", \"Stemming\", \"Lemmatization\"], label=\"Select NLP Function\")\n","    mode = gr.Radio([\"stemming\", \"lemmatization\"], visible=False)\n","    output = gr.JSON(label=\"Processed Data\")\n","    run_btn = gr.Button(\"Run NLP\")\n","\n","    nlp_choice.change(fn=toggle_visibility, inputs=nlp_choice, outputs=mode)\n","    file_input.change(fn=get_columns, inputs=file_input, outputs=column_dropdown)\n","    run_btn.click(fn=process_file, inputs=[file_input, column_dropdown, nlp_choice, mode], outputs=output)\n","\n","app = gr.TabbedInterface([text_tabs, dataset_tab], [\"Text\", \"Dataset\"])"],"metadata":{"id":"Xb_P6X5DGfqu","executionInfo":{"status":"ok","timestamp":1761041078464,"user_tz":-300,"elapsed":912,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### Launch"],"metadata":{"id":"Cb1tFtRcGyzN"}},{"cell_type":"code","source":["app.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"id":"-VqN02L8G06U","executionInfo":{"status":"ok","timestamp":1761041080043,"user_tz":-300,"elapsed":1572,"user":{"displayName":"Rayan Tanzeem","userId":"14469347407249511451"}},"outputId":"84df2a79-58ef-4148-b357-70e32164f79a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://a7032e7d1edb3f28dd.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://a7032e7d1edb3f28dd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":14}]}]}